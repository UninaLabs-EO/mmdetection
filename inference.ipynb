{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import mmcv\n",
    "from mmengine.utils import track_iter_progress\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "\n",
    "# Show the results\n",
    "from mmcv.transforms import LoadImageFromFile, Compose, Resize\n",
    "import cv2\n",
    "\n",
    "def draw_bounding_boxes(image, bounding_boxes, scores=None, score_threshold=0.05, backend_args=None, savepath=None):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1, **backend_args)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Add bounding boxes to the image\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        if scores is not None and scores[i] < score_threshold:\n",
    "            continue\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
    "\n",
    "        # Add the rectangle to the axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.axis(False)\n",
    "        # Add the score as text\n",
    "        if scores is not None:\n",
    "            score = scores[i]\n",
    "            ax.text(x_max+5, y_max+5, f'Score: {score:.2f}',\n",
    "                    color='white', fontsize=8, bbox=dict(facecolor='r', alpha=0.7))\n",
    "    \n",
    "    if savepath is not None:\n",
    "        fig.savefig(savepath)\n",
    "    # Show the image with bounding boxes\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "# define dataloader \n",
    "loader = LoadImageFromFile(to_float32=False, color_type='color', imdecode_backend='tifffile', backend_args=None)\n",
    "\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = '/home/roberto/PythonProjects/S2RAWVessel/mmdetection/configs/vfnet/vfnet_r18_fpn_1x_vessel.py'\n",
    "checkpoint_file = '/home/roberto/PythonProjects/S2RAWVessel/checkpoints/vfnet_r18_fpn_1x_vessel/20230518_152156_0.0005/epoch_239.pth'\n",
    "\n",
    "# Build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# Init visualizer\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "# The dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# test_set\n",
    "imgs=[{\"height\":1667,\"width\":2590,\"id\":1,\"file_name\":\"day1_g_18_coreg.tif\"},{\"height\":1676,\"width\":2588,\"id\":2,\"file_name\":\"day1_g_26_coreg.tif\"},{\"height\":1656,\"width\":2582,\"id\":3,\"file_name\":\"day1_g_29_coreg.tif\"},{\"height\":1676,\"width\":2590,\"id\":4,\"file_name\":\"day1_g_34_coreg.tif\"},{\"height\":1656,\"width\":2582,\"id\":5,\"file_name\":\"day1_g_35_coreg.tif\"},{\"height\":1676,\"width\":2590,\"id\":6,\"file_name\":\"day1_g_40_coreg.tif\"},{\"height\":1672,\"width\":2588,\"id\":7,\"file_name\":\"day1_g_7_coreg.tif\"},{\"height\":1671,\"width\":2587,\"id\":8,\"file_name\":\"day2_g_16_coreg.tif\"},{\"height\":1671,\"width\":2588,\"id\":9,\"file_name\":\"day2_g_19_coreg.tif\"},{\"height\":1670,\"width\":2590,\"id\":10,\"file_name\":\"day2_g_20_coreg.tif\"},{\"height\":1671,\"width\":2587,\"id\":11,\"file_name\":\"day2_g_22_coreg.tif\"},{\"height\":1682,\"width\":2590,\"id\":12,\"file_name\":\"day2_g_24_coreg.tif\"},{\"height\":1670,\"width\":2590,\"id\":13,\"file_name\":\"day2_g_38_coreg.tif\"},{\"height\":1668,\"width\":2592,\"id\":14,\"file_name\":\"day3_g_30_coreg.tif\"},{\"height\":1666,\"width\":2588,\"id\":15,\"file_name\":\"day3_g_5_coreg.tif\"},{\"height\":1665,\"width\":2584,\"id\":16,\"file_name\":\"day4_g_48_coreg.tif\"},{\"height\":1654,\"width\":2587,\"id\":17,\"file_name\":\"day4_g_58_coreg.tif\"},{\"height\":1654,\"width\":2587,\"id\":18,\"file_name\":\"day4_g_63_coreg.tif\"},{\"height\":1654,\"width\":2587,\"id\":19,\"file_name\":\"day4_g_76_coreg.tif\"},{\"height\":1669,\"width\":2592,\"id\":20,\"file_name\":\"day5_g_1_coreg.tif\"},{\"height\":1669,\"width\":2592,\"id\":21,\"file_name\":\"day5_g_43_coreg.tif\"},{\"height\":1676,\"width\":2588,\"id\":22,\"file_name\":\"day5_g_4_coreg.tif\"},{\"height\":1666,\"width\":2588,\"id\":23,\"file_name\":\"day6_g_16_coreg.tif\"},{\"height\":1665,\"width\":2584,\"id\":24,\"file_name\":\"day6_g_24_coreg.tif\"},{\"height\":1666,\"width\":2591,\"id\":25,\"file_name\":\"day6_g_25_coreg.tif\"},{\"height\":1654,\"width\":2587,\"id\":26,\"file_name\":\"day7_g_14_coreg.tif\"},{\"height\":1668,\"width\":2592,\"id\":27,\"file_name\":\"day7_g_19_coreg.tif\"},{\"height\":1666,\"width\":2591,\"id\":28,\"file_name\":\"day7_g_24_coreg.tif\"},{\"height\":1668,\"width\":2592,\"id\":29,\"file_name\":\"day7_g_27_coreg.tif\"},{\"height\":1668,\"width\":2592,\"id\":30,\"file_name\":\"day7_g_35_coreg.tif\"},{\"height\":1682,\"width\":2590,\"id\":31,\"file_name\":\"day7_g_48_coreg.tif\"},{\"height\":1654,\"width\":2587,\"id\":32,\"file_name\":\"day7_g_8_coreg.tif\"},{\"height\":1682,\"width\":2590,\"id\":33,\"file_name\":\"day8_g_15_coreg.tif\"},{\"height\":1671,\"width\":2588,\"id\":34,\"file_name\":\"day8_g_16_coreg.tif\"}]\n",
    "\n",
    "base_path = '/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/vessels/imgs/'\n",
    "outpath_base = '/home/roberto/PythonProjects/S2RAWVessel/output_results/'\n",
    "\n",
    "file_names = [x['file_name'] for x in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(file_names)):\n",
    "    # Test a single image and show the results\n",
    "    img_path =base_path + file_names[idx]  # or img = mmcv.imread(img), which will only load it once\n",
    "\n",
    "    load = loader(results={'img_path': img_path})\n",
    "    img = load['img']\n",
    "    result = inference_detector(model, img)\n",
    "    img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "    print('Inference completed. Saving image...')\n",
    "    \n",
    "    predictions = list(result.pred_instances.all_items())\n",
    "    \n",
    "    keyholder={}\n",
    "    for item in predictions:\n",
    "        keyholder[item[0]]=item[1]\n",
    "        \n",
    "    scores, boxes, labels = keyholder['scores'], keyholder['bboxes'], keyholder['labels']\n",
    "    scores = list(scores.detach().cpu().numpy())\n",
    "    boxes = list(boxes.detach().cpu().numpy())\n",
    "\n",
    "    new_name = file_names[idx].replace('.tif','.png')\n",
    "    savepath = '/home/roberto/PythonProjects/S2RAWVessel/output_results/'+new_name\n",
    "    # Draw the bounding boxes on the image\n",
    "    draw_bounding_boxes(img, boxes, scores = scores, backend_args=dict(figsize=(40, 40), dpi=100), savepath=savepath, score_threshold=0.5)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import mmcv\n",
    "from mmengine.utils import track_iter_progress\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import json \n",
    "from pathlib import Path\n",
    "\n",
    "# Show the results\n",
    "from mmcv.transforms import LoadImageFromFile, Compose, Resize\n",
    "import cv2\n",
    "\n",
    "def draw_bounding_boxes(image, bounding_boxes, scores=None, score_threshold=0.05, backend_args=None, savepath=None, gt_boxes=None):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1, **backend_args)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Add gt_boxes to the image\n",
    "    if gt_boxes is not None:\n",
    "        for i, bbox in enumerate(gt_boxes):\n",
    "            x_min, y_min, width, height = bbox\n",
    "\n",
    "            # Create a rectangle patch\n",
    "            rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                    linewidth=2, edgecolor='w', facecolor='none')\n",
    "\n",
    "            # Add the rectangle to the axes\n",
    "            ax.add_patch(rect)\n",
    "            ax.axis(False)\n",
    "\n",
    "    # Add bounding boxes to the image\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        if scores is not None and scores[i] < score_threshold:\n",
    "            continue\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                 linewidth=2, edgecolor='y', facecolor='none')\n",
    "\n",
    "        # Add the rectangle to the axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.axis(False)\n",
    "        # Add the score as text\n",
    "        if scores is not None:\n",
    "            score = scores[i]\n",
    "            ax.text(x_max+5, y_max+5, f'Score: {score:.2f}',\n",
    "                    color='white', fontsize=8, bbox=dict(facecolor='r', alpha=0.7))\n",
    "    \n",
    "    if savepath is not None:\n",
    "        fig.savefig(savepath)\n",
    "    # Show the image with bounding boxes\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "# define dataloader \n",
    "loader = LoadImageFromFile(to_float32=False, color_type='color', imdecode_backend='pillow', backend_args=None)\n",
    "\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = '/home/roberto/PythonProjects/S2RAWVessel/checkpoints/MS3/vfnet_r50_fpn_1x_ms3/20230901_112855_LR_{0.0001}_BATCH_{6}/vfnet_r50_fpn_1x_ms3.py'\n",
    "foldPath = Path('/home/roberto/PythonProjects/S2RAWVessel/checkpoints/MS3/vfnet_r50_fpn_1x_ms3/20230901_112855_LR_{0.0001}_BATCH_{6}/')\n",
    "# list all file sin folderpath:\n",
    "chkpts = list(foldPath.glob('*.pth'))\n",
    "checkpoint_file = [x for x in chkpts if 'best' in x.name][0].as_posix()\n",
    "print(checkpoint_file)\n",
    "print('Loading checkpoint: ', checkpoint_file)\n",
    "# Build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# Init visualizer\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "# The dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# READ JSON FILE TEST:\n",
    "json_file_path = '/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/MS3/annotations/test.json'\n",
    "json_file = json.load(open(json_file_path))\n",
    "imgs = json_file['images']\n",
    "\n",
    "base_path = '/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/MS3/imgs/'\n",
    "outpath_base = '/home/roberto/PythonProjects/S2RAWVessel/output_results/MS3/'\n",
    "\n",
    "file_names = [x['file_name'] for x in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_from_coco_json(coco_json_file, image_filename):\n",
    "    annotations = []\n",
    "    try:\n",
    "        with open(coco_json_file, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not find file {coco_json_file}\")\n",
    "        return annotations\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Could not decode JSON from {coco_json_file}\")\n",
    "        return annotations\n",
    "\n",
    "    # Extract image ID corresponding to the given image filename\n",
    "    image_id = None\n",
    "    for img in coco_data.get('images', []):\n",
    "        if img.get('file_name') == image_filename:\n",
    "            image_id = img.get('id')\n",
    "            break\n",
    "\n",
    "    if image_id is None:\n",
    "        print(f\"No matching image found for filename {image_filename}\")\n",
    "        return annotations\n",
    "\n",
    "    # Extract annotations for the image\n",
    "    for annotation in coco_data.get('annotations', []):\n",
    "        if annotation.get('image_id') == image_id:\n",
    "            annotations.append(annotation)\n",
    "\n",
    "    gt_boxes = [x['bbox'] for x in annotations]\n",
    "    \n",
    "    return annotations, gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# take 4 random indexes between 0 and len(filenames)\n",
    "idxs = np.random.choice(len(file_names), size=4, replace=False)\n",
    "print('Selected indexes:', idxs)\n",
    "for idx in idxs:\n",
    "    # Test a single image and show the results\n",
    "    img_path =base_path + file_names[idx]  # or img = mmcv.imread(img), which will only load it once\n",
    "    annot, gt_boxes = get_annotations_from_coco_json(json_file_path, file_names[idx])\n",
    "\n",
    "    load = loader(results={'img_path': img_path})\n",
    "    img = load['img']\n",
    "    result = inference_detector(model, img)\n",
    "    img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "    print('Inference completed. Saving image...')\n",
    "    \n",
    "    predictions = list(result.pred_instances.all_items())\n",
    "    \n",
    "    keyholder={}\n",
    "    for item in predictions:\n",
    "        keyholder[item[0]]=item[1]\n",
    "        \n",
    "    scores, boxes, labels = keyholder['scores'], keyholder['bboxes'], keyholder['labels']\n",
    "    scores = list(scores.detach().cpu().numpy())\n",
    "    boxes = list(boxes.detach().cpu().numpy())\n",
    "\n",
    "    new_name = file_names[idx].replace('.tif','.png')\n",
    "    savepath = '/home/roberto/PythonProjects/S2RAWVessel/output_results/MS3/'+new_name\n",
    "    # Draw the bounding boxes on the image\n",
    "    draw_bounding_boxes(img, boxes, scores = scores, backend_args=dict(figsize=(20, 20), dpi=100), savepath=savepath, score_threshold=0.5, gt_boxes=gt_boxes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/roberto/PythonProjects/S2RAWVessel/checkpoints/MS3/vfnet_r50_fpn_1x_ms3/20230922_075443_LR_0.001_BATCH_2_IMG_1024_MEAN_[200,154,116]_STD_[22,24,27]/best_coco_bbox_mAP_50_epoch_74.pth\n",
      "Loading checkpoint:  /home/roberto/PythonProjects/S2RAWVessel/checkpoints/MS3/vfnet_r50_fpn_1x_ms3/20230922_075443_LR_0.001_BATCH_2_IMG_1024_MEAN_[200,154,116]_STD_[22,24,27]/best_coco_bbox_mAP_50_epoch_74.pth\n",
      "Loads checkpoint by local backend from path: /home/roberto/PythonProjects/S2RAWVessel/checkpoints/MS3/vfnet_r50_fpn_1x_ms3/20230922_075443_LR_0.001_BATCH_2_IMG_1024_MEAN_[200,154,116]_STD_[22,24,27]/best_coco_bbox_mAP_50_epoch_74.pth\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/roberto/PythonProjects/S2RAWVessel/mmdetection/inference.ipynb Cella 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Besago/home/roberto/PythonProjects/S2RAWVessel/mmdetection/inference.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoading checkpoint: \u001b[39m\u001b[39m'\u001b[39m, checkpoint_file)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Besago/home/roberto/PythonProjects/S2RAWVessel/mmdetection/inference.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39m# Build the model from a config file and a checkpoint file\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Besago/home/roberto/PythonProjects/S2RAWVessel/mmdetection/inference.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=118'>119</a>\u001b[0m model \u001b[39m=\u001b[39m init_detector(config_file, checkpoint_file, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/PythonProjects/S2RAWVessel/mmdetection/mmdet/apis/inference.py:109\u001b[0m, in \u001b[0;36minit_detector\u001b[0;34m(config, checkpoint, palette, device, cfg_options)\u001b[0m\n\u001b[1;32m    106\u001b[0m             model\u001b[39m.\u001b[39mdataset_meta[\u001b[39m'\u001b[39m\u001b[39mpalette\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    108\u001b[0m model\u001b[39m.\u001b[39mcfg \u001b[39m=\u001b[39m config  \u001b[39m# save the config in the model for convenience\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    110\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab/lib/python3.8/site-packages/mmengine/model/base_model/base_model.py:202\u001b[0m, in \u001b[0;36mBaseModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_device(torch\u001b[39m.\u001b[39mdevice(device))\n\u001b[0;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:844\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[39mfor\u001b[39;00m key, buf \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    843\u001b[0m     \u001b[39mif\u001b[39;00m buf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffers[key] \u001b[39m=\u001b[39m fn(buf)\n\u001b[1;32m    846\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import mmcv\n",
    "from mmengine.utils import track_iter_progress\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import json \n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Show the results\n",
    "from mmcv.transforms import LoadImageFromFile, Compose, Resize\n",
    "import cv2\n",
    "\n",
    "def draw_bounding_boxes(image, bounding_boxes, scores=None, score_threshold=0.05, backend_args=None, savepath=None, gt_boxes=None):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1, **backend_args)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Add gt_boxes to the image\n",
    "    if gt_boxes is not None:\n",
    "        for i, bbox in enumerate(gt_boxes):\n",
    "            x_min, y_min, width, height = bbox\n",
    "\n",
    "            # Create a rectangle patch\n",
    "            rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                    linewidth=2, edgecolor='w', facecolor='none')\n",
    "\n",
    "            # Add the rectangle to the axes\n",
    "            ax.add_patch(rect)\n",
    "            ax.axis(False)\n",
    "\n",
    "    # Add bounding boxes to the image\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        if scores is not None and scores[i] < score_threshold:\n",
    "            continue\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                 linewidth=2, edgecolor='y', facecolor='none')\n",
    "\n",
    "        # Add the rectangle to the axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.axis(False)\n",
    "        # Add the score as text\n",
    "        if scores is not None:\n",
    "            score = scores[i]\n",
    "            ax.text(x_max+5, y_max+5, f'Score: {score:.2f}',\n",
    "                    color='white', fontsize=8, bbox=dict(facecolor='r', alpha=0.7))\n",
    "    \n",
    "    if savepath is not None:\n",
    "        fig.savefig(savepath)\n",
    "    # Show the image with bounding boxes\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_annotations_from_coco_json(coco_json_file, image_filename):\n",
    "    \"\"\"Get annotations from a COCO JSON file for a given image.\n",
    "\n",
    "    Args:\n",
    "        coco_json_file (str): Path to COCO JSON file.\n",
    "        image_filename (str): Filename of image.\n",
    "\n",
    "    Returns:\n",
    "        annotations (list): List of annotations for the given image.\n",
    "        gt_boxes (list): List of ground truth bounding boxes for the given image.\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    try:\n",
    "        with open(coco_json_file, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not find file {coco_json_file}\")\n",
    "        return annotations\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Could not decode JSON from {coco_json_file}\")\n",
    "        return annotations\n",
    "\n",
    "    # Extract image ID corresponding to the given image filename\n",
    "    image_id = None\n",
    "    for img in coco_data.get('images', []):\n",
    "        if img.get('file_name') == image_filename:\n",
    "            image_id = img.get('id')\n",
    "            break\n",
    "\n",
    "    if image_id is None:\n",
    "        print(f\"No matching image found for filename {image_filename}\")\n",
    "        return annotations\n",
    "\n",
    "    # Extract annotations for the image\n",
    "    for annotation in coco_data.get('annotations', []):\n",
    "        if annotation.get('image_id') == image_id:\n",
    "            annotations.append(annotation)\n",
    "\n",
    "    gt_boxes = [x['bbox'] for x in annotations]\n",
    "    \n",
    "    return annotations, gt_boxes\n",
    "\n",
    "# define dataloader \n",
    "loader = LoadImageFromFile(to_float32=False, color_type='color', imdecode_backend='pillow', backend_args=None)\n",
    "\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = '/home/roberto/PythonProjects/S2RAWVessel/checkpoints/MS3/vfnet_r50_fpn_1x_ms3/20230922_075443_LR_0.001_BATCH_2_IMG_1024_MEAN_[200,154,116]_STD_[22,24,27]/vfnet_r50_fpn_1x_ms3.py'\n",
    "foldPath = Path(config_file).parent\n",
    "# list all file sin folderpath:\n",
    "chkpts = list(foldPath.glob('*.pth'))\n",
    "checkpoint_file = [x for x in chkpts if 'best' in x.name][0].as_posix()\n",
    "print(checkpoint_file)\n",
    "print('Loading checkpoint: ', checkpoint_file)\n",
    "# Build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import mmcv\n",
    "from mmengine.utils import track_iter_progress\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "import json \n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Show the results\n",
    "from mmcv.transforms import LoadImageFromFile, Compose, Resize\n",
    "import cv2\n",
    "\n",
    "def draw_bounding_boxes(image, bounding_boxes, scores=None, score_threshold=0.05, backend_args=None, savepath=None, gt_boxes=None):\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1, **backend_args)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Add gt_boxes to the image\n",
    "    if gt_boxes is not None:\n",
    "        for i, bbox in enumerate(gt_boxes):\n",
    "            x_min, y_min, width, height = bbox\n",
    "\n",
    "            # Create a rectangle patch\n",
    "            rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                    linewidth=2, edgecolor='w', facecolor='none')\n",
    "\n",
    "            # Add the rectangle to the axes\n",
    "            ax.add_patch(rect)\n",
    "            ax.axis(False)\n",
    "\n",
    "    # Add bounding boxes to the image\n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        if scores is not None and scores[i] < score_threshold:\n",
    "            continue\n",
    "        \n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height,\n",
    "                                 linewidth=2, edgecolor='y', facecolor='none')\n",
    "\n",
    "        # Add the rectangle to the axes\n",
    "        ax.add_patch(rect)\n",
    "        ax.axis(False)\n",
    "        # Add the score as text\n",
    "        if scores is not None:\n",
    "            score = scores[i]\n",
    "            ax.text(x_max+5, y_max+5, f'Score: {score:.2f}',\n",
    "                    color='white', fontsize=8, bbox=dict(facecolor='r', alpha=0.7))\n",
    "    \n",
    "    if savepath is not None:\n",
    "        fig.savefig(savepath)\n",
    "    # Show the image with bounding boxes\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_annotations_from_coco_json(coco_json_file, image_filename):\n",
    "    \"\"\"Get annotations from a COCO JSON file for a given image.\n",
    "\n",
    "    Args:\n",
    "        coco_json_file (str): Path to COCO JSON file.\n",
    "        image_filename (str): Filename of image.\n",
    "\n",
    "    Returns:\n",
    "        annotations (list): List of annotations for the given image.\n",
    "        gt_boxes (list): List of ground truth bounding boxes for the given image.\n",
    "    \"\"\"\n",
    "    annotations = []\n",
    "    try:\n",
    "        with open(coco_json_file, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Could not find file {coco_json_file}\")\n",
    "        return annotations\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Could not decode JSON from {coco_json_file}\")\n",
    "        return annotations\n",
    "\n",
    "    # Extract image ID corresponding to the given image filename\n",
    "    image_id = None\n",
    "    for img in coco_data.get('images', []):\n",
    "        if img.get('file_name') == image_filename:\n",
    "            image_id = img.get('id')\n",
    "            break\n",
    "\n",
    "    if image_id is None:\n",
    "        print(f\"No matching image found for filename {image_filename}\")\n",
    "        return annotations\n",
    "\n",
    "    # Extract annotations for the image\n",
    "    for annotation in coco_data.get('annotations', []):\n",
    "        if annotation.get('image_id') == image_id:\n",
    "            annotations.append(annotation)\n",
    "\n",
    "    gt_boxes = [x['bbox'] for x in annotations]\n",
    "    \n",
    "    return annotations, gt_boxes\n",
    "\n",
    "# define dataloader \n",
    "loader = LoadImageFromFile(to_float32=False, color_type='color', imdecode_backend='tifffile', backend_args=None)\n",
    "displayer = LoadImageFromFile(to_float32=False, color_type='color', imdecode_backend='pillow', backend_args=None)\n",
    "\n",
    "# Specify the path to model config and checkpoint file\n",
    "config_file = '/home/roberto/PythonProjects/S2RAWVessel/checkpoints/S2L1C/vfnet_r101_fpn_1x_esa/20230919_232958_LR_0.0005_BATCH_4_IMG_2816_MEAN_[46,53,51]_STD_[30,34,42]/vfnet_r101_fpn_1x_esa.py'\n",
    "foldPath = Path(config_file).parent\n",
    "# list all file sin folderpath:\n",
    "chkpts = list(foldPath.glob('*.pth'))\n",
    "checkpoint_file = [x for x in chkpts if 'best' in x.name][0].as_posix()\n",
    "print(checkpoint_file)\n",
    "print('Loading checkpoint: ', checkpoint_file)\n",
    "# Build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "data_root = '/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/S2ESA/'\n",
    "\n",
    "model.cfg.test_dataloader = dict(\n",
    "                    batch_size=1,\n",
    "                    num_workers=2,\n",
    "                    persistent_workers=True,\n",
    "                    drop_last=False,\n",
    "                    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "                    dataset=dict(\n",
    "                        type='CocoDataset',\n",
    "                        data_root=data_root,\n",
    "                        metainfo=dict(classes=('Vessel', ), palette=[(220, 20, 60)]),\n",
    "                        ann_file='annotations/test.json',\n",
    "                        data_prefix=dict(img='imgs/'),\n",
    "                        test_mode=True,\n",
    "                        filter_cfg=dict(filter_empty_gt=True),\n",
    "                        pipeline=[\n",
    "                            dict(\n",
    "                                type='LoadImageFromFile',\n",
    "                                to_float32=True,\n",
    "                                color_type='color',\n",
    "                                imdecode_backend='tiffile',\n",
    "                                backend_args=None),\n",
    "                            dict(type='Resize', scale=(2816, 2816), keep_ratio=True),\n",
    "                            dict(type='LoadAnnotations', with_bbox=True),\n",
    "                            dict(\n",
    "                                type='PackDetInputs',\n",
    "                                meta_keys=('img', 'img_id', 'img_path', 'img_shape', 'ori_shape', 'scale', 'scale_factor', 'keep_ratio', 'homography_matrix', 'gt_bboxes', 'gt_ignore_flags', 'gt_bboxes_labels'))\n",
    "                        ],\n",
    "                        backend_args=None))\n",
    "\n",
    "\n",
    "# Init visualizer\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "# The dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# READ JSON FILE TEST:\n",
    "json_file_path = data_root + '/annotations/train.json'\n",
    "json_file = json.load(open(json_file_path))\n",
    "imgs = json_file['images']\n",
    "\n",
    "base_path = data_root + '/imgs/'\n",
    "outpath_base = '/home/roberto/PythonProjects/S2RAWVessel/output_results/S2L1C/'\n",
    "\n",
    "file_names = [x['file_name'] for x in imgs]\n",
    "\n",
    "# take 4 random indexes between 0 and len(filenames)\n",
    "idx = 0\n",
    "# Test a single image and show the results\n",
    "img_path =base_path + file_names[idx]  # or img = mmcv.imread(img), which will only load it once\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "annot, gt_boxes = get_annotations_from_coco_json(json_file_path, file_names[idx])\n",
    "\n",
    "img_path = '/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/vessels/imgs/day1_g_0_coreg.tif'\n",
    "load = loader(results={'img_path': img_path})\n",
    "# display = displayer(results={'img_path': img_path})\n",
    "# img_to_display = display['img']\n",
    "img = load['img']\n",
    "\n",
    "result = inference_detector(model, img)\n",
    "\n",
    "print('Inference completed. Saving image...')\n",
    "# get the predictions:\n",
    "predictions = list(result.pred_instances.all_items())\n",
    "keyholder={}\n",
    "for item in predictions:\n",
    "    keyholder[item[0]]=item[1]\n",
    "scores, boxes, labels = keyholder['scores'], keyholder['bboxes'], keyholder['labels']\n",
    "scores = list(scores.detach().cpu().numpy())\n",
    "boxes = list(boxes.detach().cpu().numpy())\n",
    "\n",
    "print(f'Found n {len(boxes)}  objects')\n",
    "print('scores:', scores)\n",
    "new_name = file_names[idx].replace('.tiff','.png')\n",
    "savepath = '/home/roberto/PythonProjects/S2RAWVessel/output_results/S2L1C/' + new_name\n",
    "# Draw the bounding boxes on the image\n",
    "draw_bounding_boxes(img, boxes, scores = scores, backend_args=dict(figsize=(20, 20), dpi=100), savepath=savepath, score_threshold=0.05, gt_boxes=gt_boxes)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
