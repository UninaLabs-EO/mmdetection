{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# CRATERI:\n",
    "# config_file = 'checkpoints/Craters/cascade_mask50/cascade_mask50_2022-08-05T15:15:10_768_25e_Craters_lr_0.002_CosineAnnealing/Cascade_Mask_RCNN.py'\n",
    "# checkpoint_file = 'checkpoints/Craters/cascade_mask50/cascade_mask50_2022-08-05T15:15:10_768_25e_Craters_lr_0.002_CosineAnnealing/epoch_10.pth'\n",
    "\n",
    "# RETINASWIN MULTIWAKE:\n",
    "config_file = 'checkpoints/B4/retina_swin/retina_swin_2022-07-28T22:15:36_768_50e_B4_lr_0.001_step/retinanet_swin-t-p4-w7_fpn_1x_coco.py'\n",
    "checkpoint_file = 'checkpoints/B4/retina_swin/retina_swin_2022-07-28T22:15:36_768_50e_B4_lr_0.001_step/epoch_44.pth'\n",
    "\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1390/1390 [17.0s elapsed, 0s remaining, 77.1 samples/s]      \n",
      "Name:        2023.09.01.10.57.48\n",
      "Media type:  image\n",
      "Num samples: 1390\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                   fiftyone.core.fields.ObjectIdField\n",
      "    filepath:             fiftyone.core.fields.StringField\n",
      "    tags:                 fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    vessel_detections:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    vessel_segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    vessel_coco_id:       fiftyone.core.fields.IntField\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fiftyone as fo\n",
    "\n",
    "IMAGES_DIR='/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/MS3/imgs'\n",
    "JSON_PATH='/home/roberto/PythonProjects/S2RAWVessel/mmdetection/data/MS3/annotations/test.json'\n",
    "LABEL='vessel'\n",
    "# Load COCO formatted dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    data_path=IMAGES_DIR,\n",
    "    labels_path=JSON_PATH,\n",
    "    include_id=True,\n",
    "    label_field=LABEL,)\n",
    "# Verify that the class list for our dataset was imported\n",
    "# print(coco_dataset.default_classes)  # ['airplane', 'apple', ...]\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = Path('data/DATASETS/Craters/val2017/539.jpg')\n",
    "# img = cv2.imread(img_path.as_posix())\n",
    "# shape = mmcv.imread(img_path).shape\n",
    "\n",
    "# result = inference_detector(model, img)\n",
    "# img = cv2.imread('/home/sirbastiano/Scaricati/tree-736885__480.jpg')\n",
    "\n",
    "# type(img)\n",
    "# img.shape\n",
    "# boxes, masks = result\n",
    "# plt.imshow(masks[0][5])\n",
    "# len(boxes[0])\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "\n",
    "# fig,ax = plt.subplots(figsize=(10,10))\n",
    "# ax.imshow(img)\n",
    "# for item in boxes[0]:\n",
    "#      X=item\n",
    "#      topleft = [X[0],X[1]]\n",
    "#      botright = [X[2],X[3]]\n",
    "#      score=X[4]\n",
    "\n",
    "#      rect = patches.Rectangle((topleft[0], topleft[1]), botright[0]-topleft[0], botright[1]-topleft[1], linewidth=3, edgecolor='r', facecolor='none')\n",
    "#      ax.add_patch(rect)\n",
    "# plt.show()\n",
    "# import fiftyone as fo\n",
    "segmentation = False\n",
    "\n",
    "for sample in dataset:\n",
    "    # sample = fo.Sample(filepath=\"data/DATASETS/Craters/val2017/539.jpg\")\n",
    "    # img = cv2.imread(\"data/DATASETS/Craters/val2017/539.jpg\")\n",
    "    img = cv2.imread(sample.filepath)\n",
    "    h,w,c=img.shape\n",
    "    result = inference_detector(model, img)\n",
    "\n",
    "    if segmentation:\n",
    "        boxes, masks = result # if instance segmentation method\n",
    "    else:\n",
    "        boxes = result\n",
    "\n",
    "    X = boxes[0]\n",
    "    sample[\"RetinaSwin\"] = fo.Detections(\n",
    "        detections=[\n",
    "            fo.Detection(label=LABEL, confidence=X[4], bounding_box=[X[0]/w, X[1]/h, X[2]/w-X[0]/w, X[3]/h-X[1]/h]) for X in boxes[0]\n",
    "        ]\n",
    "    )\n",
    "    sample.save()\n",
    "    \n",
    "    # print(sample)\n",
    "    # dataset.add_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=True&subscription=7e9c597a-9621-40ab-9bd6-d768804fc002\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc491d0b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to\n",
      "\n",
      "███████╗██╗███████╗████████╗██╗   ██╗ ██████╗ ███╗   ██╗███████╗\n",
      "██╔════╝██║██╔════╝╚══██╔══╝╚██╗ ██╔╝██╔═══██╗████╗  ██║██╔════╝\n",
      "█████╗  ██║█████╗     ██║    ╚████╔╝ ██║   ██║██╔██╗ ██║█████╗\n",
      "██╔══╝  ██║██╔══╝     ██║     ╚██╔╝  ██║   ██║██║╚██╗██║██╔══╝\n",
      "██║     ██║██║        ██║      ██║   ╚██████╔╝██║ ╚████║███████╗\n",
      "╚═╝     ╚═╝╚═╝        ╚═╝      ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚══════╝ v0.21.6\n",
      "\n",
      "If you're finding FiftyOne helpful, here's how you can get involved:\n",
      "\n",
      "|\n",
      "|  ⭐⭐⭐ Give the project a star on GitHub ⭐⭐⭐\n",
      "|  https://github.com/voxel51/fiftyone\n",
      "|\n",
      "|  🚀🚀🚀 Join the FiftyOne Slack community 🚀🚀🚀\n",
      "|  https://slack.voxel51.com\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(\"RetinaSwin\", F(\"confidence\") > 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    \"RetinaSwin\",\n",
    "    gt_field=f\"{LABEL}_detections\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(f\"{LABEL}_detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)\n",
    "print('Mean Average Precision:' results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = results.plot_pr_curves(classes=[LABEL])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import mmcv\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cv2\n",
    "# import os\n",
    "# import fiftyone as fo\n",
    "# from fiftyone import ViewField as F\n",
    "# global LABEL, MODEL_NAME\n",
    "\n",
    "# def model_load(model_cp, config):\n",
    "#      model = init_detector(config, model_cp, device='cuda:0')\n",
    "#      return model\n",
    "\n",
    "# def dataset_parser(IMAGES_DIR,JSON_PATH,LABEL):\n",
    "#      # Load COCO formatted dataset\n",
    "#      dataset = fo.Dataset.from_dir(\n",
    "#      dataset_type=fo.types.COCODetectionDataset,\n",
    "#      data_path=IMAGES_DIR,\n",
    "#      labels_path=JSON_PATH,\n",
    "#      include_id=True,\n",
    "#      label_field='GT',)\n",
    "#      # Verify that the class list for our dataset was imported\n",
    "#      # print(coco_dataset.default_classes)  # ['airplane', 'apple', ...]\n",
    "#      print(dataset)\n",
    "#      return dataset\n",
    "\n",
    "# # MODEL\n",
    "# CFG = 'checkpoints/Craters/cascade_mask50/cascade_mask50_2022-08-05T15:15:10_768_25e_Craters_lr_0.002_CosineAnnealing/Cascade_Mask_RCNN.py'\n",
    "# CHP = 'checkpoints/Craters/cascade_mask50/cascade_mask50_2022-08-05T15:15:10_768_25e_Craters_lr_0.002_CosineAnnealing/epoch_10.pth'\n",
    "# MODEL_NAME = 'Cascade_Mask_RCNN'\n",
    "# model = model_load(model_cp=CHP, config=CFG)\n",
    "# # DATASET\n",
    "# IMAGES_DIR='data/DATASETS/Craters/val2017'\n",
    "# JSON_PATH='data/DATASETS/Craters/annotations/instances_val2017.json'\n",
    "# LABEL='crater'\n",
    "# dataset = dataset_parser(IMAGES_DIR,JSON_PATH,LABEL)\n",
    "\n",
    "# for sample in dataset:\n",
    "#      # sample = fo.Sample(filepath=\"data/DATASETS/Craters/val2017/539.jpg\")\n",
    "#     # img = cv2.imread(\"data/DATASETS/Craters/val2017/539.jpg\")\n",
    "#     img = cv2.imread(sample.filepath)\n",
    "#     h,w,c=img.shape\n",
    "#     result = inference_detector(model, img)\n",
    "#     boxes, masks = result\n",
    "#     X = boxes[0]\n",
    "\n",
    "#     sample[MODEL_NAME] = fo.Detections(\n",
    "#         detections=[\n",
    "#             fo.Detection(label=LABEL, confidence=X[4], bounding_box=[X[0]/w, X[1]/h, X[2]/w-X[0]/w, X[3]/h-X[1]/h]) for X in boxes[0]\n",
    "#         ]\n",
    "#     )\n",
    "#     sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = dataset.filter_labels(MODEL_NAME, F(\"confidence\") > 0.75)\n",
    "\n",
    "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    MODEL_NAME,\n",
    "    gt_field=\"GT_detections\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    "    iou=0.5,\n",
    ")\n",
    "\n",
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"GT_detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "# with open(f\"{MODEL_NAME}_PR.txt\", 'w') as f: \n",
    "#      results.print_report(classes=classes_top10)\n",
    "#      f.write(results.print_report(classes=classes_top10))\n",
    "\n",
    "\n",
    "print(results.mAP())\n",
    "\n",
    "plot = results.plot_pr_curves(classes=[LABEL])\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "with open(f\"{MODEL_NAME}_PR.txt\", 'w') as f: \n",
    "     # results.print_report(classes=classes_top10)\n",
    "     f.write(results.to_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=results.plot_confusion_matrix(backend='matplotlib',)\n",
    "fig.savefig('Images/IAC22/confusion_matrix.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mmdetection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2b3a08a81cd45e0bc2a700d9045dbc9f86cb7496649aabfe12018a838ea0a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
